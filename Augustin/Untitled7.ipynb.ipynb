{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install reportlab -q"
      ],
      "metadata": {
        "id": "wcVH_VTbVUvg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.units import mm\n",
        "\n",
        "# Load the OCR JSON file\n",
        "input_file = '/content/document.json'\n",
        "output_file = '/content/document.pdf'\n",
        "\n",
        "def create_pdf_from_ocr(json_path, output_pdf):\n",
        "    # Open the JSON file\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        ocr_data = json.load(f)\n",
        "\n",
        "    # Use A4 page size\n",
        "    page_width, page_height = A4\n",
        "\n",
        "    # Create a new PDF canvas\n",
        "    c = canvas.Canvas(output_pdf, pagesize=A4)\n",
        "\n",
        "    # Full document text\n",
        "    document_text = ocr_data.get('text', '')\n",
        "\n",
        "    # Set default font size (you can adjust this as needed)\n",
        "    font_size = 10\n",
        "    c.setFont(\"Helvetica\", font_size)\n",
        "\n",
        "    # Calculate scaling factors\n",
        "    first_page = ocr_data['pages'][0]\n",
        "    original_width = first_page['dimension']['width']\n",
        "    original_height = first_page['dimension']['height']\n",
        "    scale_x = page_width / original_width\n",
        "    scale_y = page_height / original_height\n",
        "\n",
        "    # Loop through pages and extract layout information\n",
        "    for page in ocr_data['pages']:\n",
        "        # Loop through blocks of text\n",
        "        for block in page['blocks']:\n",
        "            # Extract bounding box information\n",
        "            if 'boundingBox' in block['layout']:\n",
        "                block_bbox = block['layout']['boundingBox']\n",
        "                start_x = block_bbox.get('left', 0) * scale_x\n",
        "                start_y = page_height - (block_bbox.get('top', 0) * scale_y)  # Invert y-axis for PDF coordinates\n",
        "                block_width = block_bbox.get('width', 0) * scale_x\n",
        "            elif 'boundingPoly' in block['layout']:\n",
        "                block_bbox = block['layout']['boundingPoly']\n",
        "                if 'vertices' in block_bbox:\n",
        "                    vertices = block_bbox['vertices']\n",
        "                    start_x = vertices[0].get('x', 0) * scale_x\n",
        "                    start_y = page_height - (vertices[0].get('y', 0) * scale_y)  # Invert y-axis for PDF coordinates\n",
        "                    block_width = (vertices[1].get('x', 0) - vertices[0].get('x', 0)) * scale_x\n",
        "                elif 'normalizedVertices' in block_bbox:\n",
        "                    vertices = block_bbox['normalizedVertices']\n",
        "                    start_x = vertices[0].get('x', 0) * page_width\n",
        "                    start_y = page_height - (vertices[0].get('y', 0) * page_height)  # Invert y-axis for PDF coordinates\n",
        "                    block_width = (vertices[1].get('x', 0) - vertices[0].get('x', 0)) * page_width\n",
        "            else:\n",
        "                print(f\"Warning: Unable to determine bounding box for block: {block}\")\n",
        "                continue\n",
        "\n",
        "            # Extract text segments\n",
        "            text_segments = block['layout']['textAnchor'].get('textSegments', [])\n",
        "            if text_segments:\n",
        "                start_index = text_segments[0].get('startIndex', 0)\n",
        "                end_index = text_segments[0].get('endIndex', 0)\n",
        "\n",
        "                # Extract the text content from the document using the indices\n",
        "                text_content = document_text[int(start_index):int(end_index)]\n",
        "\n",
        "                # Replace '/n' with actual newlines\n",
        "                text_content = text_content.replace('/n', '\\n')\n",
        "\n",
        "                # Split the text into lines based on newline characters\n",
        "                text_lines = text_content.split('\\n')\n",
        "\n",
        "                # Process each line\n",
        "                for line in text_lines:\n",
        "                    # Word-wrap the line to fit within the bounding box width\n",
        "                    wrapped_lines = wrap_text(c, line, block_width, font_size)\n",
        "\n",
        "                    # Draw each wrapped line of text on the PDF\n",
        "                    for wrapped_line in wrapped_lines:\n",
        "                        c.drawString(start_x, start_y, wrapped_line)\n",
        "                        start_y -= font_size * 1.2  # Move down to the next line\n",
        "\n",
        "                        # Check if we run out of space on the current page\n",
        "                        if start_y < font_size:\n",
        "                            c.showPage()  # Create a new page\n",
        "                            c.setFont(\"Helvetica\", font_size)\n",
        "                            start_y = page_height - font_size\n",
        "\n",
        "        # Finish the current page\n",
        "        c.showPage()\n",
        "\n",
        "    # Save the PDF\n",
        "    c.save()\n",
        "\n",
        "def wrap_text(canvas, text, max_width, font_size):\n",
        "    \"\"\"\n",
        "    Splits the text into lines that fit within the given width.\n",
        "    \"\"\"\n",
        "    words = text.split(' ')\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "\n",
        "    for word in words:\n",
        "        # Check if the current line + new word fits in the width\n",
        "        if canvas.stringWidth(current_line + word, \"Helvetica\", font_size) < max_width:\n",
        "            current_line += word + \" \"\n",
        "        else:\n",
        "            lines.append(current_line.strip())\n",
        "            current_line = word + \" \"\n",
        "\n",
        "    # Append the last line\n",
        "    if current_line:\n",
        "        lines.append(current_line.strip())\n",
        "\n",
        "    return lines\n",
        "\n",
        "# Create the PDF from OCR JSON\n",
        "create_pdf_from_ocr(input_file, output_file)\n",
        "\n",
        "print(f\"PDF created at {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KGL3HSRcs5k",
        "outputId": "bec90b52-bb4f-4193-8bb8-3ff8647d6458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF created at /content/document.pdf\n"
          ]
        }
      ]
    }
  ]
}