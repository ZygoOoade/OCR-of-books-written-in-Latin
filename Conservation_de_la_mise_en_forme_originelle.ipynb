{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-bWL1Y_r6fvW"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-vision pillow pandas python-docx scikit-learn -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from collections import Counter\n",
        "from google.cloud import vision\n",
        "import re\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] ='credentials.json'\n",
        "client = vision.ImageAnnotatorClient()\n",
        "WORD = re.compile(r\"\\w+\")"
      ],
      "metadata": {
        "id": "4PYgtyjL6hkN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Chemin vers le dossier\n",
        "dossier = \"piccolomini - good crop\"\n",
        "\n",
        "# Parcourir tous les fichiers du dossier\n",
        "for filename in os.listdir(dossier):\n",
        "    # Vérifier si le nom du fichier contient au moins 3 chiffres à la fin\n",
        "    if filename[-7:-4].isdigit():\n",
        "        # Extraire les trois derniers chiffres\n",
        "        nouveau_nom = filename[-7:-4] + filename[-4:]\n",
        "\n",
        "        # Construire les chemins complets pour l'ancien et le nouveau nom\n",
        "        ancien_chemin = os.path.join(dossier, filename)\n",
        "        nouveau_chemin = os.path.join(dossier, nouveau_nom)\n",
        "\n",
        "        # Renommer le fichier\n",
        "        os.rename(ancien_chemin, nouveau_chemin)\n",
        "        print(f\"Renommé: {filename} -> {nouveau_nom}\")\n",
        "    else:\n",
        "        print(f\"Ignoré: {filename} (ne correspond pas au format attendu)\")\n",
        "\n",
        "print(\"Renommage terminé.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLjsnQZzIyvr",
        "outputId": "9afe6aeb-fd25-4d3a-ec1c-3c15be7fd159"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renommé: Piccolomini_page_16.jpg -> 016.jpg\n",
            "Renommé: Piccolomini_page_26.jpg -> 026.jpg\n",
            "Renommé: Piccolomini_page_4.jpg -> 004.jpg\n",
            "Renommé: Piccolomini_page_45.jpg -> 045.jpg\n",
            "Renommé: Piccolomini_page_13.jpg -> 013.jpg\n",
            "Renommé: Piccolomini_page_29.jpg -> 029.jpg\n",
            "Ignoré: .ipynb_checkpoints (ne correspond pas au format attendu)\n",
            "Renommé: Piccolomini_page_6.jpg -> 006.jpg\n",
            "Renommé: Piccolomini_page_23.jpg -> 023.jpg\n",
            "Renommé: Piccolomini_page_30.jpg -> 030.jpg\n",
            "Renommé: Piccolomini_page_18.jpg -> 018.jpg\n",
            "Renommé: Piccolomini_page_46.jpg -> 046.jpg\n",
            "Renommé: Piccolomini_page_5.jpg -> 005.jpg\n",
            "Renommé: Piccolomini_page_19.jpg -> 019.jpg\n",
            "Renommé: Piccolomini_page_14.jpg -> 014.jpg\n",
            "Renommé: Piccolomini_page_38.jpg -> 038.jpg\n",
            "Renommé: Piccolomini_page_36.jpg -> 036.jpg\n",
            "Renommé: Piccolomini_page_10.jpg -> 010.jpg\n",
            "Renommé: Piccolomini_page_11.jpg -> 011.jpg\n",
            "Renommé: Piccolomini_page_7.jpg -> 007.jpg\n",
            "Renommé: Piccolomini_page_42.jpg -> 042.jpg\n",
            "Renommé: Piccolomini_page_9.jpg -> 009.jpg\n",
            "Renommé: Piccolomini_page_17.jpg -> 017.jpg\n",
            "Renommé: Piccolomini_page_20.jpg -> 020.jpg\n",
            "Renommé: Piccolomini_page_27.jpg -> 027.jpg\n",
            "Renommé: Piccolomini_page_8.jpg -> 008.jpg\n",
            "Renommé: Piccolomini_page_34.jpg -> 034.jpg\n",
            "Renommé: Piccolomini_page_40.jpg -> 040.jpg\n",
            "Renommé: Piccolomini_page_24.jpg -> 024.jpg\n",
            "Renommé: Piccolomini_page_12.jpg -> 012.jpg\n",
            "Renommé: Piccolomini_page_22.jpg -> 022.jpg\n",
            "Renommé: Piccolomini_page_15.jpg -> 015.jpg\n",
            "Renommé: Piccolomini_page_28.jpg -> 028.jpg\n",
            "Renommé: Piccolomini_page_21.jpg -> 021.jpg\n",
            "Renommé: Piccolomini_page_32.jpg -> 032.jpg\n",
            "Renommé: Piccolomini_page_44.jpg -> 044.jpg\n",
            "Renommé: Piccolomini_page_25.jpg -> 025.jpg\n",
            "Renommage terminé.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "from google.cloud import vision\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "from docx.enum.section import WD_ORIENT\n",
        "from PIL import Image\n",
        "\n",
        "def detect_text(path):\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    with open(path, \"rb\") as image_file:\n",
        "        content = image_file.read()\n",
        "    image = vision.Image(content=content)\n",
        "    response = client.document_text_detection(image=image)\n",
        "    texts = response.text_annotations\n",
        "    if response.error.message:\n",
        "        raise Exception(\n",
        "            \"{}\\nFor more info on error messages, check: \"\n",
        "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
        "        )\n",
        "    return texts[0].description if texts else \"\"\n",
        "\n",
        "def process_images(folder_path):\n",
        "    doc = Document()\n",
        "\n",
        "    # Change orientation to landscape\n",
        "    section = doc.sections[0]\n",
        "    section.orientation = WD_ORIENT.LANDSCAPE\n",
        "    section.page_width, section.page_height = section.page_height, section.page_width\n",
        "\n",
        "    # Find min_i and max_i\n",
        "    min_i = 1000\n",
        "    max_i = -1\n",
        "    for i in range(1000):\n",
        "        image_name = f\"{i:03d}.jpg\"\n",
        "        image_path = os.path.join(folder_path, image_name)\n",
        "        if os.path.exists(image_path):\n",
        "            min_i = min(min_i, i)\n",
        "            max_i = max(max_i, i)\n",
        "\n",
        "    if min_i > max_i:\n",
        "        print(\"No images found in the specified folder.\")\n",
        "        return\n",
        "\n",
        "    table = doc.add_table(rows=1, cols=2)\n",
        "    table.style = 'Table Grid'\n",
        "    hdr_cells = table.rows[0].cells\n",
        "    hdr_cells[0].text = f'Pages from {min_i:03d} to {max_i:03d}'\n",
        "    hdr_cells[1].text = 'OCR Text'\n",
        "\n",
        "    for i in range(min_i, max_i + 1):\n",
        "        image_name = f\"{i:03d}.jpg\"\n",
        "        image_path = os.path.join(folder_path, image_name)\n",
        "\n",
        "        if os.path.exists(image_path):\n",
        "            ocr_text = detect_text(image_path)\n",
        "\n",
        "            row_cells = table.add_row().cells\n",
        "\n",
        "            # Insert image\n",
        "            paragraph = row_cells[0].paragraphs[0]\n",
        "            run = paragraph.add_run()\n",
        "            run.add_picture(image_path, width=Inches(3))  # Adjust width as needed\n",
        "\n",
        "            row_cells[1].text = ocr_text\n",
        "\n",
        "    doc.save('output.docx')\n",
        "    print(f\"OCR results and images from {min_i:03d} to {max_i:03d} have been saved to output.docx in landscape orientation\")\n",
        "\n",
        "# Main execution\n",
        "folder_path = \"/content/folder\"\n",
        "process_images(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf7GxeMsrc9r",
        "outputId": "24a27717-5a0d-4a93-daae-435a0612b334"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR results and images from 017 to 018 have been saved to output.docx in landscape orientation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "from google.cloud import vision\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "from docx.enum.section import WD_ORIENT\n",
        "from PIL import Image\n",
        "\n",
        "def detect_text(path):\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    with open(path, \"rb\") as image_file:\n",
        "        content = image_file.read()\n",
        "    image = vision.Image(content=content)\n",
        "    response = client.document_text_detection(image=image)\n",
        "    texts = response.text_annotations\n",
        "    if response.error.message:\n",
        "        raise Exception(\n",
        "            \"{}\\nFor more info on error messages, check: \"\n",
        "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
        "        )\n",
        "    return texts[0].description if texts else \"\"\n",
        "\n",
        "def process_images(folder_path):\n",
        "    doc = Document()\n",
        "\n",
        "    # Landscape orientation\n",
        "    section = doc.sections[0]\n",
        "    section.orientation = WD_ORIENT.LANDSCAPE\n",
        "    section.page_width, section.page_height = section.page_height, section.page_width\n",
        "\n",
        "    table = doc.add_table(rows=1, cols=2)\n",
        "    table.style = 'Table Grid'\n",
        "    hdr_cells = table.rows[0].cells\n",
        "\n",
        "    for i in range(1000):  # Loop from 000 to 999\n",
        "        image_name = f\"{i:03d}.jpg\"\n",
        "        image_path = os.path.join(folder_path, image_name)\n",
        "\n",
        "        if os.path.exists(image_path):\n",
        "            ocr_text = detect_text(image_path)\n",
        "\n",
        "            row_cells = table.add_row().cells\n",
        "\n",
        "            # Insert image\n",
        "            paragraph = row_cells[0].paragraphs[0]\n",
        "            run = paragraph.add_run()\n",
        "            run.add_picture(image_path, width=Inches(4))\n",
        "\n",
        "            row_cells[1].text = ocr_text\n",
        "\n",
        "    doc.save('output.docx')\n",
        "    print(\"OCR results and images have been saved to output.docx in landscape orientation\")\n",
        "\n",
        "# Main execution\n",
        "folder_path = \"/content/folder\"\n",
        "process_images(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kj0uZcbX4zk",
        "outputId": "0495b792-af63-42b6-ca8b-7fcd029704d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR results and images have been saved to output.docx in landscape orientation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from google.cloud import vision\n",
        "from docx import Document\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def detect_text(path):\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "\n",
        "    with open(path, \"rb\") as image_file:\n",
        "        content = image_file.read()\n",
        "\n",
        "    image = vision.Image(content=content)\n",
        "\n",
        "    response = client.document_text_detection(image=image)\n",
        "    texts = response.text_annotations\n",
        "    ocr_text = []\n",
        "\n",
        "    for text in texts:\n",
        "        ocr_text.append(f\"\\r\\n{text.description}\")\n",
        "\n",
        "    if response.error.message:\n",
        "        raise Exception(\n",
        "            \"{}\\nFor more info on error messages, check: \"\n",
        "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
        "        )\n",
        "    return ocr_text\n",
        "\n",
        "def save_text_to_docx(text, output_filename):\n",
        "    doc = Document()\n",
        "    paragraphs = text.split('\\n')\n",
        "    for paragraph in paragraphs:\n",
        "        doc.add_paragraph(paragraph.strip())\n",
        "    doc.save(output_filename)\n",
        "\n",
        "def display_markdown_with_breaks(text):\n",
        "    display(Markdown(text))\n",
        "\n",
        "# Main execution\n",
        "image_path = \"/content/a/Piccolomini_page_10.jpg\"\n",
        "initial_name = \"Piccolomini_page_10\"  # You can change this as needed\n",
        "\n",
        "# Detect text\n",
        "ocr_result = detect_text(image_path)\n",
        "\n",
        "# Save to docx\n",
        "output_filename = f\"{initial_name}_ocr.docx\"\n",
        "save_text_to_docx(ocr_result[0], output_filename)\n",
        "\n",
        "print(f\"OCR text has been saved to {output_filename}\")\n",
        "\n",
        "# Display the text in Markdown format (optional)\n",
        "display_markdown_with_breaks(ocr_result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "lFOMWUAhKoG_",
        "outputId": "ccb37b6b-c985-4e9c-ce79-04db75500da1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR text has been saved to Piccolomini_page_10_ocr.docx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\r\nME CHA N.\nII\nre ipfa ab omni materia feiunctas ac feparatas confyde/\nrat, mentes fcilicet illas fimplices, nulliq mutabilitati\nobnoxias: veluti intelligentia funt, & in primis Deus ip\nfe optimus maximus. reliqua vero Metaphifica pars in\ncomunifsimis verfatur: veluti in eo quod eft, cuius par/\ntes atq proprietates perfcrutatur. Quo fit, vt ex hac\nMetaphifica parte, omnia qua tanquam cognita in ca\nteris fcientiis affummuntur, fi á quopiam abnegentur,\nprobari & oftendi pofsint. quamobrem circa eadem la/\nborant Metaphificus & Dialecticus, circa communifsi/\nma fcilicet: diuerfa tamen ratione, vt apud Alexandru\nfiue Ephefium Michaelem, abunde videri poteft. Sed\nde Diuina,& naturali philofophia hactenus,cum ad rem\nmodo noftram non pertineant. Cæterum Mathemati\nca, quæ contemplatricis philofophiæ tertia reftat pars,\nquia quantum, magnitudinem fcilicet & multitudinem,\neafqz nullo habito refpectu ad materiam in quá firmen/\ntur, confyderat: iccirco duæ funt eius partes, altera nu\nmerum contemplans, Arithmetica fcilicet: reliqua ve/\nro continuam magnitudinem fpeculans, quam Geome\ntriam nuncupamus,quę tametfi numerus ex continui di/\nuifione nafcatur, pofterior tamen atqz ignobilior eft, q\nfit arithmetica, multas ob caufas, quac apud Boetium in\nArithmeticis haberi poffunt. Vtraq; autem harum ma\nthematica partium, alias rurfus complectitur partes: no\nquidem fellularias artes ( vt quidam volunt, qui illas\nfub decimo Euclidis libro non recte collocant, in quo\nlibro potentia tantum habetur magnitudinum) fed\nB ii Arith/"
          },
          "metadata": {}
        }
      ]
    }
  ]
}